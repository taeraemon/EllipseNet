{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using tensorboardX\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x7faef6804fd0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "lib_path = os.path.join('../src/lib')\n",
    "if not lib_path in sys.path:\n",
    "    sys.path.append(lib_path)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from fhd_opts import opts\n",
    "from models.model import create_model, load_model, save_model\n",
    "from models.data_parallel import DataParallel\n",
    "from logger import Logger\n",
    "from datasets.dataset_factory import get_dataset\n",
    "from trains.train_factory import train_factory\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib_path = '../../Rotated_IoU/'\n",
    "if not lib_path in sys.path:\n",
    "    sys.path.append(lib_path)\n",
    "from utiles import box2corners\n",
    "from oriented_iou_loss import cal_diou, cal_giou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fix size testing.\n",
      "training chunk_sizes: [32]\n",
      "The output will be saved to  /data/cc/workspace/Repository/CenterNet/scripts/../../exp/eldet/default\n",
      "heads {'hm': 2, 'reg': 2, 'l': 1, 'ratio_al': 1, 'ratio_bl': 1, 'theta': 1, 'sincos': 2}\n",
      "Namespace(K=2, aggr_weight=0.0, agnostic_ex=False, angle_bins_weight=0, arch='dla_34', aug_ddd=0.5, aug_rot=0, batch_size=32, cat_spec_wh=False, center_thresh=0.1, chunk_sizes=[32], data_dir='/data/cc/Data/CHD/fake_data/', dataset='coco_fhd', debug=0, debug_dir='/data/cc/workspace/Repository/CenterNet/scripts/../../exp/eldet/default/debug', debugger_theme='white', demo='', dense_hp=False, dense_wh=False, dep_weight=1, dim_weight=1, down_ratio=4, ellipse_reg_weight=0, ellipse_weight=1, eval_oracle_dep=False, eval_oracle_hm=False, eval_oracle_hmhp=False, eval_oracle_hp_offset=False, eval_oracle_kps=False, eval_oracle_offset=False, eval_oracle_wh=False, exp_dir='/data/cc/workspace/Repository/CenterNet/scripts/../../exp/eldet', exp_id='default', fix_res=True, flip=0.5, flip_test=False, gaussian_noise=False, gpus=[0], gpus_str='0', head_conv=256, heads={'hm': 2, 'reg': 2, 'l': 1, 'ratio_al': 1, 'ratio_bl': 1, 'theta': 1, 'sincos': 2}, hide_data_time=False, hm_hp=True, hm_hp_weight=1, hm_weight=1, hp_weight=1, input_h=512, input_res=512, input_w=512, iou_weight=1, keep_res=False, kitti_split='3dop', load_model='', lr=0.000125, lr_step=[80, 120, 200, 400], master_batch_size=32, mean=array([[[0.216, 0.216, 0.216]]], dtype=float32), metric='loss', mse_loss=False, nms=False, no_color_aug=False, norm_wh=False, not_cuda_benchmark=False, not_hm_hp=False, not_prefetch_test=False, not_rand_crop=False, not_reg_bbox=False, not_reg_hp_offset=False, not_reg_offset=False, num_angle_bins=0, num_classes=2, num_epochs=140, num_iters=-1, num_stacks=1, num_workers=4, off_weight=1, output_h=128, output_res=128, output_w=128, pad=31, peak_thresh=0.2, print_iter=0, rect_mask=False, reg_bbox=True, reg_hp_offset=True, reg_loss='l1', reg_offset=True, resume=False, root_dir='/data/cc/workspace/Repository/CenterNet/scripts/../..', rot_weight=1, rotate=0, save_all=False, save_dir='/data/cc/workspace/Repository/CenterNet/scripts/../../exp/eldet/default', save_image=False, scale=0.2, scores_thresh=0.1, seed=317, shift=0.1, sincos_weight=1, std=array([[[0.222, 0.222, 0.222]]], dtype=float32), task='eldet', test=False, test_scales=[1.0], theta_weight=1, trainval=False, val_intervals=5, vis_thresh=0.3, wh_weight=0.1)\n"
     ]
    }
   ],
   "source": [
    "args = ['eldet']\n",
    "opt = opts().parse(args)\n",
    "# opt.data_dir = '/data/cc/Data/CHD/detection/'\n",
    "opt.data_dir = '/data/cc/Data/CHD/fake_data/'\n",
    "opt.num_classes = 2\n",
    "opt.dataset = 'coco_fhd'\n",
    "opt.sincos_weight = 1\n",
    "\n",
    "torch.manual_seed(opt.seed)\n",
    "torch.backends.cudnn.benchmark = not opt.not_cuda_benchmark and not opt.test\n",
    "Dataset = get_dataset(opt.dataset, opt.task)\n",
    "opt = opts().update_dataset_info_and_set_heads(opt, Dataset)\n",
    "print(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = Logger(opt)\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = opt.gpus_str\n",
    "opt.device = torch.device('cuda' if opt.gpus[0] >= 0 else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model...\n"
     ]
    }
   ],
   "source": [
    "print('Creating model...')\n",
    "model = create_model(opt.arch, opt.heads, opt.head_conv)\n",
    "optimizer = torch.optim.Adam(model.parameters(), opt.lr)\n",
    "start_epoch = 0\n",
    "if opt.load_model != '':\n",
    "    model, optimizer, start_epoch = load_model(\n",
    "      model, opt.load_model, optimizer, opt.resume, opt.lr, opt.lr_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Trainer = train_factory[opt.task]\n",
    "trainer = Trainer(opt, model, optimizer)\n",
    "trainer.set_device(opt.gpus, opt.chunk_sizes, opt.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up data...\n",
      "==> initializing Fetal Heart Disease val data.\n",
      "loading annotations into memory...\n",
      "Done (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "Loaded val 400 samples\n",
      "==> initializing Fetal Heart Disease train data.\n",
      "loading annotations into memory...\n",
      "Done (t=0.06s)\n",
      "creating index...\n",
      "index created!\n",
      "Loaded train 1600 samples\n"
     ]
    }
   ],
   "source": [
    "print('Setting up data...')\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    Dataset(opt, 'val'), \n",
    "    batch_size=1, \n",
    "    shuffle=False,\n",
    "    num_workers=1,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "if opt.test:\n",
    "    _, preds = trainer.val(0, val_loader)\n",
    "    val_loader.dataset.run_eval(preds, opt.save_dir)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    Dataset(opt, 'train'), \n",
    "    batch_size=opt.batch_size, \n",
    "    shuffle=True,\n",
    "    num_workers=opt.num_workers,\n",
    "    pin_memory=True,\n",
    "    drop_last=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    }
   ],
   "source": [
    "%pdb on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cc/miniconda3/lib/python3.7/site-packages/torch/nn/functional.py:1625: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/home/cc/miniconda3/lib/python3.7/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/cc/miniconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([32, 1, 128, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-72892212b18d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_epoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmark\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_all\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'last'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mlog_dict_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch: {} |'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch: {} |'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/cc/workspace/Repository/CenterNet/src/lib/trains/base_trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epoch, data_loader)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/data/cc/workspace/Repository/CenterNet/src/lib/trains/base_trainer.py\u001b[0m in \u001b[0;36mrun_epoch\u001b[0;34m(self, phase, epoch, data_loader)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'meta'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m           \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m       \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_stats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_with_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/cc/workspace/Repository/CenterNet/src/lib/trains/base_trainer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_stats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_stats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/cc/workspace/Repository/CenterNet/src/lib/trains/eldet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, outputs, batch)\u001b[0m\n\u001b[1;32m     60\u001b[0m         wh_loss += self.crit_reg(\n\u001b[1;32m     61\u001b[0m           \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'l'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reg_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m           batch['ind'], batch['l']) / opt.num_stacks\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0;31m# if opt.dense_wh:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;31m#   mask_weight = batch['dense_wh_mask'].sum() + 1e-4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/cc/workspace/Repository/CenterNet/src/lib/models/losses.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, output, mask, ind, target)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;31m# loss = F.l1_loss(pred * mask, target * mask, reduction='elementwise_mean')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/data/cc/workspace/Repository/CenterNet/src/lib/models/losses.py\u001b[0m(181)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    179 \u001b[0;31m        \u001b[0;31m# loss = F.l1_loss(pred * mask, target * mask, reduction='elementwise_mean')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    180 \u001b[0;31m        \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 181 \u001b[0;31m        \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    182 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    183 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> output\n",
      "*** RuntimeError: cuda runtime error (710) : device-side assert triggered at /pytorch/aten/src/THC/THCCachingHostAllocator.cpp:278\n"
     ]
    }
   ],
   "source": [
    "logger = Logger(opt)\n",
    "print('Starting training...')\n",
    "best = 1e10\n",
    "for epoch in range(start_epoch + 1, opt.num_epochs + 1):\n",
    "    mark = epoch if opt.save_all else 'last'\n",
    "    log_dict_train, _ = trainer.train(epoch, train_loader)\n",
    "    logger.write('epoch: {} |'.format(epoch))\n",
    "    print('epoch: {} |'.format(epoch))\n",
    "    for k, v in log_dict_train.items():\n",
    "        logger.scalar_summary('train_{}'.format(k), v, epoch)\n",
    "        logger.write('{} {:8f} | '.format(k, v))\n",
    "    if opt.val_intervals > 0 and epoch % opt.val_intervals == 0:\n",
    "        save_model(os.path.join(opt.save_dir, 'model_{}.pth'.format(mark)), \n",
    "                 epoch, model, optimizer)\n",
    "        with torch.no_grad():\n",
    "            log_dict_val, preds = trainer.val(epoch, val_loader)\n",
    "        for k, v in log_dict_val.items():\n",
    "            logger.scalar_summary('val_{}'.format(k), v, epoch)\n",
    "            logger.write('{} {:8f} | '.format(k, v))\n",
    "        if log_dict_val[opt.metric] < best:\n",
    "            best = log_dict_val[opt.metric]\n",
    "            save_model(os.path.join(opt.save_dir, 'model_best.pth'), \n",
    "                   epoch, model)\n",
    "    else:\n",
    "        save_model(os.path.join(opt.save_dir, 'model_last.pth'), \n",
    "                 epoch, model, optimizer)\n",
    "    logger.write('\\n')\n",
    "    if epoch in opt.lr_step:\n",
    "        save_model(os.path.join(opt.save_dir, 'model_{}.pth'.format(epoch)), \n",
    "                 epoch, model, optimizer)\n",
    "        lr = opt.lr * (0.1 ** (opt.lr_step.index(epoch) + 1))\n",
    "        print('Drop LR to', lr)\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "#     break\n",
    "logger.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iter_id, batch in enumerate(train_loader): # len(batch) = 6\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Designed for calculating Rotated IoU Loss\n",
    "class IoULoss_test(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(IoULoss_test, self).__init__()\n",
    "  \n",
    "  def forward(self, output, batch):\n",
    "        \n",
    "        \n",
    "        \n",
    "    bbox1 = torch.tensor([[[125, 125, 100, 50, math.pi]]]).cuda()\n",
    "    bbox2 = torch.tensor([[[125, 125, 100, 50, 0.0 * math.pi]]]).cuda()\n",
    "    print(bbox1.shape, bbox2.shape)\n",
    "    print(bbox1, bbox2)\n",
    "    iou_loss, iou = cal_diou(bbox1, bbox2)\n",
    "    iou_loss, iou\n",
    "     \n",
    "    pred = _transpose_and_gather_feat(output, ind)\n",
    "    mask = mask.unsqueeze(2).expand_as(pred).float()\n",
    "    # loss = F.l1_loss(pred * mask, target * mask, reduction='elementwise_mean')\n",
    "    loss = angle_loss(pred * mask, target * mask, size_average=False, use_smooth_l1=self.use_smooth_l1)\n",
    "    loss = loss / (mask.sum() + 1e-4)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_loader:\n",
    "    batch_input = batch['input'].cuda()\n",
    "    break\n",
    "\n",
    "output = trainer.model_with_loss.model(batch_input)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output, batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.decode import eldet_decode, _topk, _nms\n",
    "def _gather_feat(feat, ind, mask=None):\n",
    "    dim  = feat.size(2)\n",
    "    ind  = ind.unsqueeze(2).expand(ind.size(0), ind.size(1), dim)\n",
    "    feat = feat.gather(1, ind)\n",
    "    if mask is not None:\n",
    "        mask = mask.unsqueeze(2).expand_as(feat)\n",
    "        feat = feat[mask]\n",
    "        feat = feat.view(-1, dim)\n",
    "    return feat\n",
    "\n",
    "def _transpose_and_gather_feat(feat, ind):\n",
    "    feat = feat.permute(0, 2, 3, 1).contiguous()\n",
    "    feat = feat.view(feat.size(0), -1, feat.size(3))\n",
    "    feat = _gather_feat(feat, ind)\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def decode_output_4iou(output, K=2): # Decode output for iou loss\n",
    "    heat = output['hm'].sigmoid_() # (B, 2, w, h)\n",
    "    l = output['l'] # (B, 1, w, h)\n",
    "    ratio_al = output[\"ratio_al\"] # (B, 1, w, h)\n",
    "    ratio_ba = output[\"ratio_ba\"] # (B, 1, w, h)\n",
    "    theta = output[\"theta\"] # (B, 2, w, h)\n",
    "    reg = output['reg'] if opt.reg_offset else None # (B, 2, w, h)\n",
    "\n",
    "    batch, cat, height, width = heat.size()\n",
    "    heat = _nms(heat)\n",
    "    scores, inds, clses, ys, xs = _topk(heat, K=K)\n",
    "\n",
    "    if reg is not None:\n",
    "        reg = _transpose_and_gather_feat(reg, inds)  # (B, K, 1)\n",
    "        reg = reg.view(batch, K, 2)\n",
    "        xs = xs.view(batch, K, 1) + reg[:, :, 0:1]\n",
    "        ys = ys.view(batch, K, 1) + reg[:, :, 1:2]\n",
    "    else:\n",
    "        xs = xs.view(batch, K, 1) + 0.5\n",
    "        ys = ys.view(batch, K, 1) + 0.5\n",
    "\n",
    "    l = _transpose_and_gather_feat(l, inds) # (B, K, 1)\n",
    "    ratio_al = _transpose_and_gather_feat(ratio_al, inds) # (B, K, 1)\n",
    "    ratio_ba = _transpose_and_gather_feat(ratio_ba, inds) # (B, K, 1)\n",
    "    theta = _transpose_and_gather_feat(theta, inds) # (B, K, 1)\n",
    "\n",
    "    a = l * ratio_al\n",
    "    b = a * ratio_ba\n",
    "    theta = theta * math.pi\n",
    "\n",
    "    bboxes = torch.cat([xs, ys, 2*a, 2*b, theta], dim=2)\n",
    "    return bboxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_output = decode_output_4iou(output)\n",
    "bbox_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dets = eldet_decode(hm, l, ratio_al=ratio_al, ratio_ba=ratio_ba, theta=theta, \n",
    "                          reg=reg, cat_spec_wh=opt.cat_spec_wh, K=opt.K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = dets[..., 4:5]\n",
    "ys = dets[..., 5:6]\n",
    "l = dets[..., 6:7]\n",
    "ratio_al = dets[..., 7:8]\n",
    "ratio_ba = dets[..., 8:9]\n",
    "xs.shape, ys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heat = _nms(batch['hm'])\n",
    "reg = batch['reg']\n",
    "l = batch['l']\n",
    "ratio_al = batch['ratio_al']\n",
    "ratio_ba = batch['ratio_ba']\n",
    "theta = batch['theta']\n",
    "scores, inds, clses, ys, xs = _topk(heat, K=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "a = l * ratio_al\n",
    "b = a * ratio_ba\n",
    "theta = theta * math.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_label_4iou(label, K=2): # Decode label for iou loss\n",
    "    heat = label['hm']\n",
    "    reg = label['reg']\n",
    "    l = label['l']\n",
    "    ratio_al = label['ratio_al']\n",
    "    ratio_ba = label['ratio_ba']\n",
    "    theta = label['theta']\n",
    "    batch, cat, height, width = heat.size()\n",
    "\n",
    "    # perform nms on heatmaps\n",
    "    heat = _nms(heat)\n",
    "      \n",
    "    scores, inds, clses, ys, xs = _topk(heat, K=K) # (B, K)\n",
    "    if reg is not None:\n",
    "        reg = reg.view(batch, K, 2)\n",
    "        xs = xs.view(batch, K, 1) + reg[:, :, 0:1]\n",
    "        ys = ys.view(batch, K, 1) + reg[:, :, 1:2]\n",
    "    else:\n",
    "        xs = xs.view(batch, K, 1) + 0.5\n",
    "        ys = ys.view(batch, K, 1) + 0.5\n",
    "    a = l * ratio_al\n",
    "    b = a * ratio_ba\n",
    "    theta = theta * math.pi\n",
    "\n",
    "    bboxes = torch.cat([xs, ys, 2*a, 2*b, theta], dim=2)\n",
    "    return bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_label = decode_label_4iou(label).cuda()\n",
    "bbox_output = decode_output_4iou(output).cuda()\n",
    "print(bbox_label[0], bbox_output[0])\n",
    "bbox_output.shape, bbox_output.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cal_diou(bbox_output, bbox_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
