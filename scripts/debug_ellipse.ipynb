{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "lib_path = os.path.join('../src/lib')\n",
    "if not lib_path in sys.path:\n",
    "    sys.path.append(lib_path)\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from fhd_opts import opts\n",
    "from models.model import create_model, load_model, save_model\n",
    "from models.data_parallel import DataParallel\n",
    "from logger import Logger\n",
    "from datasets.dataset_factory import get_dataset\n",
    "from trains.train_factory import train_factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fix size testing.\n",
      "training chunk_sizes: [32]\n",
      "The output will be saved to  /data/cc/workspace/Repository/CenterNet/scripts/../../exp/eldet/default\n",
      "heads {'hm': 2, 'reg': 2, 'l': 1, 'ratio_al': 1, 'ratio_ba': 1, 'theta': 1}\n",
      "Namespace(K=2, aggr_weight=0.0, agnostic_ex=False, arch='dla_34', aug_ddd=0.5, aug_rot=0, batch_size=32, cat_spec_wh=False, center_thresh=0.1, chunk_sizes=[32], data_dir='/data/cc/Data/CHD/detection/', dataset='coco_fhd', debug=0, debug_dir='/data/cc/workspace/Repository/CenterNet/scripts/../../exp/eldet/default/debug', debugger_theme='white', demo='', dense_hp=False, dense_wh=False, dep_weight=1, dim_weight=1, down_ratio=4, ellipse_reg_weight=1, ellipse_weight=1, eval_oracle_dep=False, eval_oracle_hm=False, eval_oracle_hmhp=False, eval_oracle_hp_offset=False, eval_oracle_kps=False, eval_oracle_offset=False, eval_oracle_wh=False, exp_dir='/data/cc/workspace/Repository/CenterNet/scripts/../../exp/eldet', exp_id='default', fix_res=True, flip=0.5, flip_test=False, gpus=[0], gpus_str='0', head_conv=256, heads={'hm': 2, 'reg': 2, 'l': 1, 'ratio_al': 1, 'ratio_ba': 1, 'theta': 1}, hide_data_time=False, hm_hp=True, hm_hp_weight=1, hm_weight=1, hp_weight=1, input_h=512, input_res=512, input_w=512, keep_res=False, kitti_split='3dop', load_model='', lr=0.000125, lr_step=[90, 120], master_batch_size=32, mean=array([[[0., 0., 0.]]], dtype=float32), metric='loss', mse_loss=False, nms=False, no_color_aug=False, norm_wh=False, not_cuda_benchmark=False, not_hm_hp=False, not_prefetch_test=False, not_rand_crop=False, not_reg_bbox=False, not_reg_hp_offset=False, not_reg_offset=False, num_classes=2, num_epochs=140, num_iters=-1, num_stacks=1, num_workers=4, off_weight=1, output_h=128, output_res=128, output_w=128, pad=31, peak_thresh=0.2, print_iter=0, rect_mask=False, reg_bbox=True, reg_hp_offset=True, reg_loss='l1', reg_offset=True, resume=False, root_dir='/data/cc/workspace/Repository/CenterNet/scripts/../..', rot_weight=1, rotate=0, save_all=False, save_dir='/data/cc/workspace/Repository/CenterNet/scripts/../../exp/eldet/default', scale=0.4, scores_thresh=0.1, seed=317, shift=0.1, std=array([[[1., 1., 1.]]], dtype=float32), task='eldet', test=False, test_scales=[1.0], trainval=False, val_intervals=5, vis_thresh=0.3, wh_weight=0.1)\n"
     ]
    }
   ],
   "source": [
    "args = ['eldet']\n",
    "opt = opts().parse(args)\n",
    "opt.data_dir = '/data/cc/Data/CHD/detection/'\n",
    "opt.num_classes = 2\n",
    "opt.dataset = 'coco_fhd'\n",
    "\n",
    "torch.manual_seed(opt.seed)\n",
    "torch.backends.cudnn.benchmark = not opt.not_cuda_benchmark and not opt.test\n",
    "Dataset = get_dataset(opt.dataset, opt.task)\n",
    "opt = opts().update_dataset_info_and_set_heads(opt, Dataset)\n",
    "print(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hm': 2, 'reg': 2, 'l': 1, 'ratio_al': 1, 'ratio_ba': 1, 'theta': 1}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = Logger(opt)\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = opt.gpus_str\n",
    "opt.device = torch.device('cuda' if opt.gpus[0] >= 0 else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model...\n"
     ]
    }
   ],
   "source": [
    "print('Creating model...')\n",
    "model = create_model(opt.arch, opt.heads, opt.head_conv)\n",
    "optimizer = torch.optim.Adam(model.parameters(), opt.lr)\n",
    "start_epoch = 0\n",
    "if opt.load_model != '':\n",
    "    model, optimizer, start_epoch = load_model(\n",
    "      model, opt.load_model, optimizer, opt.resume, opt.lr, opt.lr_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Trainer = train_factory[opt.task]\n",
    "trainer = Trainer(opt, model, optimizer)\n",
    "trainer.set_device(opt.gpus, opt.chunk_sizes, opt.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up data...\n",
      "==> initializing Fetal Heart Disease val data.\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loaded val 100 samples\n",
      "==> initializing Fetal Heart Disease train data.\n",
      "loading annotations into memory...\n",
      "Done (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "Loaded train 424 samples\n"
     ]
    }
   ],
   "source": [
    "print('Setting up data...')\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    Dataset(opt, 'val'), \n",
    "    batch_size=1, \n",
    "    shuffle=False,\n",
    "    num_workers=1,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "if opt.test:\n",
    "    _, preds = trainer.val(0, val_loader)\n",
    "    val_loader.dataset.run_eval(preds, opt.save_dir)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    Dataset(opt, 'train'), \n",
    "    batch_size=opt.batch_size, \n",
    "    shuffle=True,\n",
    "    num_workers=opt.num_workers,\n",
    "    pin_memory=True,\n",
    "    drop_last=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cc/miniconda3/lib/python3.7/site-packages/torch/nn/functional.py:1625: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/home/cc/miniconda3/lib/python3.7/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/cc/miniconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([32, 1, 128, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 |\n",
      "epoch: 2 |\n",
      "epoch: 3 |\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-72892212b18d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_epoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmark\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_all\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'last'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mlog_dict_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch: {} |'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch: {} |'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/cc/workspace/Repository/CenterNet/src/lib/trains/base_trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epoch, data_loader)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/data/cc/workspace/Repository/CenterNet/src/lib/trains/base_trainer.py\u001b[0m in \u001b[0;36mrun_epoch\u001b[0;34m(self, phase, epoch, data_loader)\u001b[0m\n\u001b[1;32m     71\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0mbatch_time\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "logger = Logger(opt)\n",
    "print('Starting training...')\n",
    "best = 1e10\n",
    "for epoch in range(start_epoch + 1, opt.num_epochs + 1):\n",
    "    mark = epoch if opt.save_all else 'last'\n",
    "    log_dict_train, _ = trainer.train(epoch, train_loader)\n",
    "    logger.write('epoch: {} |'.format(epoch))\n",
    "    print('epoch: {} |'.format(epoch))\n",
    "    for k, v in log_dict_train.items():\n",
    "        logger.scalar_summary('train_{}'.format(k), v, epoch)\n",
    "        logger.write('{} {:8f} | '.format(k, v))\n",
    "    if opt.val_intervals > 0 and epoch % opt.val_intervals == 0:\n",
    "        save_model(os.path.join(opt.save_dir, 'model_{}.pth'.format(mark)), \n",
    "                 epoch, model, optimizer)\n",
    "        with torch.no_grad():\n",
    "            log_dict_val, preds = trainer.val(epoch, val_loader)\n",
    "        for k, v in log_dict_val.items():\n",
    "            logger.scalar_summary('val_{}'.format(k), v, epoch)\n",
    "            logger.write('{} {:8f} | '.format(k, v))\n",
    "        if log_dict_val[opt.metric] < best:\n",
    "            best = log_dict_val[opt.metric]\n",
    "            save_model(os.path.join(opt.save_dir, 'model_best.pth'), \n",
    "                   epoch, model)\n",
    "    else:\n",
    "        save_model(os.path.join(opt.save_dir, 'model_last.pth'), \n",
    "                 epoch, model, optimizer)\n",
    "    logger.write('\\n')\n",
    "    if epoch in opt.lr_step:\n",
    "        save_model(os.path.join(opt.save_dir, 'model_{}.pth'.format(epoch)), \n",
    "                 epoch, model, optimizer)\n",
    "        lr = opt.lr * (0.1 ** (opt.lr_step.index(epoch) + 1))\n",
    "        print('Drop LR to', lr)\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "#     break\n",
    "logger.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iter_id, batch in enumerate(train_loader): # len(batch) = 6\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch['wh'].shape, batch['reg'].shape, batch['l'].shape, batch['ratio_al'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model\n",
    "output = model(batch['input'].cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output[0]['reg'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.l1_loss(pred * mask, target * mask, size_average=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# idx += 1\n",
    "plt.imshow(batch['input'][idx][1, :], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch['hm'][idx][0, :].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx += 1\n",
    "img = np.array(batch['input'][idx][0, :])\n",
    "w, h = batch['wh'][idx][0]\n",
    "cy, cx = np.where(batch['hm'][idx][0, :]==1.)\n",
    "cx, cy = 4 * cx[0], 4 * cy[0]\n",
    "l = batch['l'][idx][0]\n",
    "# a = batch['a'][idx][0]\n",
    "# b = batch['b'][idx][0]\n",
    "a = batch['ratio_al'][idx][0] * l\n",
    "b = batch['ratio_ba'][idx][0] * a\n",
    "theta = batch['theta'][idx][0]\n",
    "angle = int(theta * 180)\n",
    "lung_pt1 = (int(cx - 0.5 * l), int(cy - 0.5 * l))\n",
    "lung_pt2 = (int(cx + 0.5 * l), int(cy + 0.5 * l))\n",
    "img = cv2.rectangle(img=img, pt1=lung_pt1, pt2=lung_pt2, color=(0.5), thickness=5)\n",
    "img = cv2.ellipse(img, (cx, cy), (int(a), int(b)), angle, 0.0, 360.0, (1), thickness=3)\n",
    "# l = cv2.rectangle(img=l, pt1=heart_pt1, pt2=heart_pt2, color=(2), thickness=5)\n",
    "\n",
    "w, h = batch['wh'][idx][1]\n",
    "cy, cx = np.where(batch['hm'][idx][1, :]==1.)\n",
    "cx, cy = 4 * cx[0], 4 * cy[0]\n",
    "l = batch['l'][idx][1]\n",
    "# a = batch['a'][idx][0]\n",
    "# b = batch['b'][idx][0]\n",
    "a = batch['ratio_al'][idx][1] * l\n",
    "b = batch['ratio_ba'][idx][1] * a\n",
    "theta = batch['theta'][idx][1]\n",
    "angle = int(theta * 180)\n",
    "heart_pt1 = (int(cx - 0.5 * l), int(cy - 0.5 * l))\n",
    "heart_pt2 = (int(cx + 0.5 * l), int(cy + 0.5 * l))\n",
    "img = cv2.rectangle(img=img, pt1=heart_pt1, pt2=heart_pt2, color=(1.5), thickness=5)\n",
    "img = cv2.ellipse(img, (cx, cy), (int(a), int(b)), angle, 0.0, 360.0, (2), thickness=3)\n",
    "\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_loss = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_loss(r_a ** 2 * (1 + r_b ** 2), torch.tensor(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_a = batch['ratio_al'][idx][1]\n",
    "r_b = batch['ratio_ba'][idx][1]\n",
    "r_a ** 2 * (1 + r_b ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img = np.array(batch['input'][idx][0, :])\n",
    "w, h = batch['wh'][idx][0]\n",
    "cy, cx = np.where(batch['hm'][idx][0, :]==1.)\n",
    "cx, cy = 4 * cx[0], 4 * cy[0]\n",
    "l = batch['l'][idx][0]\n",
    "a = batch['a'][idx][0]\n",
    "b = batch['b'][idx][0]\n",
    "theta = batch['theta'][idx][0]\n",
    "angle = int(theta * 180)\n",
    "lung_pt1 = (int(cx - 0.5 * l), int(cy - 0.5 * l))\n",
    "lung_pt2 = (int(cx + 0.5 * l), int(cy + 0.5 * l))\n",
    "img = cv2.rectangle(img=img, pt1=lung_pt1, pt2=lung_pt2, color=(1), thickness=5)\n",
    "img = cv2.ellipse(img, (cx, cy), (int(a), int(b)), angle, 0.0, 360.0, (1), thickness=3)\n",
    "# l = cv2.rectangle(img=l, pt1=heart_pt1, pt2=heart_pt2, color=(2), thickness=5)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch['theta'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, h = np.where(batch['hm'][idx][1, :]==1.)\n",
    "w, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch['wh'][idx][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "6333 // 128, 6333 % 128"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
